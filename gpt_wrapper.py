# gpt_wrapper.py

import os
import tiktoken
from openai import OpenAI
from dotenv import load_dotenv
from lore_loader import load_lore

load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# === –ú–Ü–°–¢–û –ì–†–ê–í–¶–Ø ===
current_city = None

def set_current_city(city_name: str):
    global current_city
    current_city = city_name

def get_current_city():
    return current_city

# === –õ—ñ—á–∏–ª—å–Ω–∏–∫ —Ç–æ–∫–µ–Ω—ñ–≤ ===
def count_tokens(messages, model="gpt-4.1"):
    try:
        enc = tiktoken.encoding_for_model(model)
    except KeyError:
        enc = tiktoken.get_encoding("cl100k_base")

    num_tokens = 0
    for message in messages:
        num_tokens += 4  # –∫–æ–∂–Ω–µ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –º–∞—î –æ–≤–µ—Ä—Ö–µ–¥
        for key, value in message.items():
            num_tokens += len(enc.encode(value))
    num_tokens += 2  # –ø—Ä–∏–º—ñ—Ç–∫–∞ –Ω–∞ –∫—ñ–Ω–µ—Ü—å
    print(f"üìè –°–∫—ñ–ª—å–∫–∏ —Ç–æ–∫–µ–Ω—ñ–≤ —É –∑–∞–ø–∏—Ç—ñ: {num_tokens}")
    return num_tokens

def call_gpt(messages, temperature=0.9, model="gpt-4.1", max_tokens=2000, add_lore=True) -> str:
    """
    –í–∏–∫–ª–∏–∫–∞—î GPT-4o –∑ –ø–µ—Ä–µ–¥–∞–Ω–∏–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏.
    –î–æ–¥–∞—î –ø—Ä–∏–∫–ª–∞–¥ —Å—Ü–µ–Ω–∏ —Ç–∞ –ª–æ—Ä –º—ñ—Å—Ç–∞ –¥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ.
    """

    # –ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –ø—Ä–∏–∫–ª–∞–¥ —Å—Ü–µ–Ω–∏
    example_scene_path = os.path.join("lore", "shared", "example_scene.txt")
    example_scene_text = ""
    if os.path.exists(example_scene_path):
        with open(example_scene_path, "r", encoding="utf-8") as f:
            example_scene_text = f.read()
    else:
        print("[!] –§–∞–π–ª –ø—Ä–∏–∫–ª–∞–¥—É —Å—Ü–µ–Ω–∏ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ.")

    # –ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –∞–∫—Ç—É–∞–ª—å–Ω–∏–π –ª–æ—Ä –¥–ª—è –ø–æ—Ç–æ—á–Ω–æ–≥–æ –º—ñ—Å—Ç–∞
    from gpt_wrapper import get_current_city
    city_name = get_current_city()
    lore_text = ""
    if city_name:
        from gpt_wrapper import smart_load_city_lore
        lore_text = smart_load_city_lore(city_name, max_tokens=20000)

    # –§–æ—Ä–º—É—î–º–æ —Ñ—ñ–Ω–∞–ª—å–Ω—ñ messages
    system_messages = []

    # 1. –ü—Ä–∏–∫–ª–∞–¥ —Å—Ü–µ–Ω–∏
    if example_scene_text:
        system_messages.append({
            "role": "system",
            "content": f"üìñ –ü–†–ò–ö–õ–ê–î –°–¶–ï–ù–ò –î–õ–Ø –°–¢–ò–õ–Æ:\n{example_scene_text}"
        })

    # 2. –õ–æ—Ä —Ç—ñ–ª—å–∫–∏ –ø–æ —Ç–µ–≥—É
    if add_lore and lore_text:
        system_messages.append({
            "role": "system",
            "content": f"üìö –õ–û–† –¢–Ü–õ–¨–ö–ò –ü–û –¢–ï–ì–£:\n–í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π —Ç—ñ–ª—å–∫–∏ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∏, —â–æ –º–∞—é—Ç—å —Ç–µ–≥ #{city_name.lower()}.\n–ù–µ –∑–º—ñ—à—É–π —Ä—ñ–∑–Ω—ñ –º—ñ—Å—Ç–∞. –Ø–∫—â–æ —Ç–µ–≥ –Ω–µ —Å–ø—ñ–≤–ø–∞–¥–∞—î ‚Äî —ñ–≥–Ω–æ—Ä—É–π.\n\n{lore_text}"
        })

    full_messages = system_messages + messages

    # –õ—ñ—á–∏–º–æ —Ç–æ–∫–µ–Ω–∏
    count_tokens(full_messages, model=model)

    response = client.chat.completions.create(
        model=model,
        messages=full_messages,
        temperature=temperature,
        max_tokens=max_tokens
    )
    return response.choices[0].message.content.strip()

def smart_load_city_lore(city_name: str, max_tokens: int = 20000, model_name="gpt-4o") -> str:
    """
    –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î –ª–æ—Ä –º—ñ—Å—Ç–∞ –∑ –ø—Ä—ñ–æ—Ä–∏—Ç–µ—Ç–æ–º: —Å–ø–æ—á–∞—Ç–∫—É –ø–µ—Ä—Å–æ–Ω–∞–∂—ñ —ñ –æ—Ä–≥–∞–Ω—ñ–∑–∞—Ü—ñ—ó, –ø–æ—Ç—ñ–º —Ä–µ—à—Ç–∞.
    """
    base_folder = "lore"
    encoding = tiktoken.encoding_for_model(model_name)

    # –°–ø–∏—Å–æ–∫ —É –Ω–æ–≤–æ–º—É –ø—Ä—ñ–æ—Ä–∏—Ç–µ—Ç—ñ
    priority_files = [
        f"{city_name.lower()}_–ø–µ—Ä—Å–æ–Ω–∞–∂—ñ.txt",
        f"{city_name.lower()}_–æ—Ä–≥–∞–Ω—ñ–∑–∞—Ü—ñ—ó.txt",
        f"{city_name.lower()}_–º—ñ—Å—Ç–æ.txt",
        f"{city_name.lower()}_–æ–∫–æ–ª–∏—Ü—ñ.txt",
        f"{city_name.lower()}_—Ä–∞–π–æ–Ω_–ª—é–¥–µ–π.txt",
        f"{city_name.lower()}_—Ä–∞–π–æ–Ω_–∂–∞–±–æ–ª—é–¥—ñ–≤.txt",
        f"{city_name.lower()}_—Ä–∞–π–æ–Ω_–¥–≤–æ—Ä—Ñ—ñ–≤.txt",
        f"{city_name.lower()}_—Ä–∞–π–æ–Ω_–µ–ª—å—Ñ—ñ–≤.txt",
        f"{city_name.lower()}_–ª–æ–∫–∞—Ü—ñ—ó.txt",

    ]

    shared_folder = os.path.join(base_folder, "shared")
    shared_files = []

    if os.path.isdir(shared_folder):
        shared_files = [file for file in os.listdir(shared_folder) if file.endswith(".txt")]

    all_files = priority_files + [os.path.join("shared", file) for file in shared_files]

    lore_texts = []
    current_tokens = 0

    for filename in all_files:
        file_path = os.path.join(base_folder, filename)
        if os.path.exists(file_path):
            with open(file_path, "r", encoding="utf-8") as f:
                text = f.read()
                tokens = encoding.encode(text)
                if current_tokens + len(tokens) <= max_tokens:
                    lore_texts.append(text)
                    current_tokens += len(tokens)
                else:
                    # –Ø–∫—â–æ —Ç–µ–∫—Å—Ç –ø–µ—Ä–µ–≤–∏—â—É—î –ª—ñ–º—ñ—Ç ‚Äî –±—ñ–ª—å—à–µ –Ω–µ –¥–æ–¥–∞—î–º–æ
                    continue
        else:
            print(f"[!] –§–∞–π–ª {filename} –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ, –ø—Ä–æ–ø—É—â–µ–Ω–æ.")

    return "\n\n".join(lore_texts)



